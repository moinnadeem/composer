train_dataset:
  glue:
    task: rte
    tokenizer_name: bert-base-uncased
    split: train
    max_seq_length: 256
    shuffle: false
    drop_last: false
evaluators:
  - evaluator:
      label: glue_rte
      eval_dataset:
        glue:
          task: rte
          tokenizer_name: bert-base-uncased
          split: validation
          max_seq_length: 256
          shuffle: false
          drop_last: false
      metric_names:
        - Accuracy
      summary:
        - max
model:
  bert_classification:
    num_labels: 2
    use_pretrained: true
    tokenizer_name: bert-base-uncased
    pretrained_model_name: bert-base-uncased
optimizer:
  decoupled_adamw:
    lr: 5.0e-5
    betas:
      - 0.9
      - 0.98
    eps: 1.0e-06
    weight_decay: 0.0
schedulers:
  - linear_decay_with_warmup:
      t_warmup: 0.02dur
loggers:
  - progress_bar: {}
  - wandb:
      tags: gold_may_11
max_duration: 30ep
train_batch_size: 16
eval_batch_size: 48
seed: 19
device:
  gpu: {}
dataloader:
  pin_memory: true
  persistent_workers: true
  num_workers: 8
  timeout: 0
  prefetch_factor: 2
grad_accum: 1
precision: amp
grad_clip_norm: None
validate_every_n_batches: 1000
validate_every_n_epochs: 1
callbacks:
  - lr_monitor: {}
load_path: https://storage.googleapis.com/moin_bert_checkpoints/moin-bert-baseline/ep1-ba68796-rank0-wct38583/checkpoints/ep5-ba40910-rank0-wct5362
load_weights_only: true
load_strict_model_weights: false
load_chunk_size: 8192
load_ignore_model_keys:
  - module.classifier.weight
  - module.classifier.bias
