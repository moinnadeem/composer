name: cola-pareto-curves # Name of the sweep - it'll be used in run names
project: cola-pareto-curves # Name of the Weights and Biases project to use
image: mosaicml/pytorch_internal:moin  # Name of the docker image to use
git_repo: https://github.com/moinnadeem/composer.git # Name of the git repo to clone - can be full URL or path under github.com
git_branch: moin/act # Name of the git branch/tag/commit to use
command: >-
  python3.8 -m venv env

  source env/bin/activate

  git clone https://github.com/moinnadeem/apex /root/apex

  cd /root/apex

  pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113

  pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./

  git clone {{ git_repo }} /root/composer

  cd /root/composer

  echo 'Checking out composer branch {{ git_branch }}'

  git checkout {{ git_branch }}

  pip install -e ".[all]"

  composer -n {{ parameters['_n_gpus'] }} examples/run_composer_trainer.py
  -f /mnt/config/parameters.yaml

instance: r1z1-g1-a100  # Name of the instance you want to run on, e.g. r1z1-g8-a100
run_type: convergence  # Type of run you want to perform (convergence is default and only one support currently)
models: cola_debugging  # The name of the model you want to use - should match the name of a YAML file in your local composer "models" directory unless you are fully specifying model parameters in the `parameters` section
algorithms:
  - act_fn_search
parameters:  # Any parameter overrides you want to use IN EVERY RUN should be specified here
  _n_gpus: 1
  algorithms:
    act_fn_search:
      use_gated: true
      use_rmsnorm: false
      use_fln: true
      act_fn_name: gelu 
grid:  # Any parameter overrides you want to sweep over should be specified here. Use "dot-syntax" to recurse into the nested parameters
  optimizer.decoupled_adamw.lr:
    - 1.0e-5
  optimizer.decoupled_adamw.weight_decay:
    - 0.0
  grad_clip_norm:
    - None
  train_batch_size:
    - 32
  load_path_format:
    # GEGELU + Fused
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it3500_1957.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it14000_7746.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it24500_13524.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it35000_19298.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it45500_25072.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it56000_30847.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it66500_36619.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_gegelu_fused/rank_0/bert_checkpoints/it68796_37886.tar
  seed:
    - 1
    - 2
    - 3
    - 4
