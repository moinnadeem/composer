name: cola-baseline # Name of the sweep - it'll be used in run names
project: cola-baseline # Name of the Weights and Biases project to use
image: mosaicml/pytorch_internal:moin  # Name of the docker image to use
git_repo: https://github.com/moinnadeem/composer.git # Name of the git repo to clone - can be full URL or path under github.com
git_branch: moin/cola_sweeps # Name of the git branch/tag/commit to use
command: >-
  git clone {{ git_repo }} /root/composer

  cd /root/composer

  echo 'Checking out composer branch {{ git_branch }}'

  git checkout {{ git_branch }}

  pip install --user -e ".[all]"

  git clone https://github.com/moinnadeem/apex /root/apex

  cd /root/apex

  pip install --user -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./

  cd /root/composer

  pip install -U --pre triton

  composer -n {{ parameters['_n_gpus'] }} examples/run_composer_trainer.py
  -f /mnt/config/parameters.yaml

instance: r1z1-g1-a100  # Name of the instance you want to run on, e.g. r1z1-g8-a100
run_type: convergence  # Type of run you want to perform (convergence is default and only one support currently)
models: cola_debugging  # The name of the model you want to use - should match the name of a YAML file in your local composer "models" directory unless you are fully specifying model parameters in the `parameters` section
parameters:  # Any parameter overrides you want to use IN EVERY RUN should be specified here
  _n_gpus: 1
grid:  # Any parameter overrides you want to sweep over should be specified here. Use "dot-syntax" to recurse into the nested parameters
  optimizer.decoupled_adamw.lr:
    - 1.0e-5
    - 2.0e-5
  optimizer.decoupled_adamw.weight_decay:
    - 0.0
  grad_clip_norm:
    - None
  train_batch_size:
    - 32
  load_path:
    # BASELINE
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it3500_2248.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it14000_8977.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it24500_15698.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it35000_22428.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it45500_29156.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it56000_35960.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it66500_42793.tar
    - https://storage.googleapis.com/bert_checkpoints/bert_baseline/rank_0/bert_checkpoints/it68796_44284.tar
  seed:
    - 1
    - 2
    - 3
    - 4
  max_duration:
    - 10ep
    - 20ep
    - 50ep
    - 100ep
